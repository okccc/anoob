### clickHouse
```shell script
# 优点：性能超过大部分列式存储数据库,标准sql语法适合OLAP
# 缺点：不支持事务,单表查询很快但是join性能一般
# 高吞吐写入能力：采用类LSM Tree结构先将数据顺序写入在后台定期合并,benchmark测试显示能达到50~200M/S
# 数据分区与线程级并行：将数据划分为多个partition通过多个cpu并行处理,单条查询就能利用整机所有cpu速度极快,但是不适合高qps的并发查询
# 关联查询很慢,因为默认把右表加载到内存而不管表的大小,所以适合存已经关联了各种事实表和维度表的大宽表,再进行统计分析
# [clickhouse官网](https://clickhouse.com/)
```

### 表引擎
```clickhouse
-- MergeTree系列引擎支持分区和索引,是clickHouse最强大的表引擎,地位相当于mysql的innodb
-- 建表语句
create table t_order(
    id UInt32,
    sku_id String,
    total_amount Decimal(16,2),
    create_time Datetime
 ) engine=MergeTree
   partition by toYYYYMMDD(create_time)
   primary key (id)
   order by (id,sku_id);
-- 插入数据
insert into t_order values
(101,'sku_001',1000.00,'2020-06-01 12:00:00') ,
(102,'sku_002',2000.00,'2020-06-01 11:00:00'),
(102,'sku_004',2500.00,'2020-06-01 12:00:00'),
(102,'sku_002',2000.00,'2020-06-01 13:00:00'),
(102,'sku_002',12000.00,'2020-06-01 13:00:00'),
(102,'sku_002',600.00,'2020-06-02 12:00:00');

-- partition by分区(可选)
-- 类似hive分区,可以降低扫描范围优化查询速度,不设置就只有一个分区,涉及跨分区的查询统计时ck会以分区为单位并行处理,
-- 任何批次的数据写入时都会产生一个临时分区,大概在10分钟后ck会自动执行合并操作,等不及也可以手动合并optimize table t1 final;

-- primary key主键(可选)
-- 只提供了数据的一级索引,并不是唯一约束,所以ck不能保证幂等性,主键设定的依据是查询语句的where条件,根据主键可以定位到索引粒度避免全表扫描
-- index granularity是指稀疏索引中两个相邻索引对应数据的间隔,MergeTree默认是8192,不建议修改除非该列存在大量重复值,比如几万行才有不同数据
-- 稀疏索引的好处就是可以用很少的索引定位更多的数据,但是只能定位到索引粒度的第一行,然后再一点点扫描

-- order by(必选)
-- 设定分区内的数据按照哪些字段进行排序,是MergeTree引擎的唯一必填项,比主键更重要,当不设置主键时去重和汇总等操作会按照order by的字段进行处理
-- 主键必须是order by的前缀字段,比如order by字段是(id,sku_id),那么主键必须是id或者(id,sku_id)
    
-- 数据TTL：管理表和列的生命周期
-- 列级别TTL：建表时在列后面添加 TTL create_time+interval 10 SECOND/MINUTE/HOUR/DAY/WEEK/MONTH/QUARTER/YEAR
-- 表级别TTL：alter table t1 MODIFY TTL create_time + INTERVAL 10 SECOND
-- 10秒后数据不会立马清空,ck会定时在后台自动合并分区,等不及可以手动合并optimize table t1 final使TTL立即生效

create table visitor_stats (
    stt        DateTime,
    edt        DateTime,
    vc         String,
    ch         String,
    ar         String,
    is_new     String,
    uv_ct      UInt64,
    pv_ct      UInt64,
    sv_ct      UInt64,
    uj_ct      UInt64,
    dur_sum    UInt64,
    ts         UInt64
 ) engine=ReplacingMergeTree(ts)  -- 可以保证数据幂等性  
   partition by toYYYYMMDD(stt)
   order by (stt,edt,is_new,vc,ch,ar);
```

### crud
```clickhouse
-- insert
insert into t_order values(101,'sku_001',1000.00,'2020-06-01 12:00:00');
insert into t_order select column1,column2,column3 from t2;
-- update/delete属于Mutation操作,修改和删除会导致放弃目标数据的原有分区并重建新分区,所以很"重"并且不支持事务,尽量批量变更不要频繁操作小数据
-- Mutation语句分两步执行,先新增数据分区并把旧分区打上逻辑失效标记,等到触发分区合并时才会删除旧数据释放磁盘空间,一般不开放给用户而是由管理员完成
alter table t_order delete where sku_id ='sku_001';
alter table t_order update total_amount=toDecimal32(2000.00,2) where id =102;
-- select
-- with rollup: 从右至左去掉维度进行小计
select id,sku_id,sum(total_amount) from t_order group by id,sku_id with rollup;
-- with cube: 从右至左去掉维度进行小计,再从左至右去掉维度进行小计
select id,sku_id,sum(total_amount) from t_order group by id,sku_id with cube;
-- with totals: 只计算合计
select id,sku_id,sum(total_amount) from t_order group by id,sku_id with totals;
-- alter
alter table t1 add column col2 String after col1;
alter table t1 modify column col2 String;
alter table t1 drop column col2;
-- 导出数据
clickhouse-client --query "select * from t_order where id > 100" --format CSVWithNames > /opt/module/data/rs1.csv
```

### 副本和分片
```shell script
# 副本主要是保障数据的高可用,降低丢数据风险,但是每个节点都要容纳全量数据,不能解决数据的横向扩容问题
# 分片将一份完整的数据进行切分分布到不同节点上,再通过Distributed表引擎把数据拼接起来一起使用,表引擎是中间件本身不存储数据
# ck集群比如3分片2副本共6个节点,生产中通常会做副本但是没有分片,避免降低查询性能以及操作集群的复杂性
```