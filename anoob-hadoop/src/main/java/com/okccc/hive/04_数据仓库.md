### 数据仓库
```shell script
# 数据仓库四大特性：面向主题、集成的、稳定的、反映历史变化
# 输入系统：埋点日志产生的用户行为数据,javaee后台产生的业务数据,爬虫数据
# 输出系统：报表系统,用户画像,推荐系统,机器学习
# 数据采集：sqoop/canal/flume/kafka
# 数据存储：mysql/hdfs/hbase/redis/mongodb
# 数据计算：hive/spark/flink
# 数据查询：presto/kylin/impala/clickhouse
# 数据可视化：Echarts/Superset/QuickBI(收费)/DataV(收费)
# 任务调度：Azkaban(中小型公司)/Ozzie(功能全面)/DolphinScheduler(界面友好)/Airflow(Python写的)
# 集群监控：Zabbix/Prometheus
# 元数据管理：Atlas
# 权限管理：Ranger(HDP)/Sentry(CDH,两家公司合并后已废除)

# 集群规模
# 假设日活用户100万,平均每个用户100条日志,平均每条日志1K,每日新增100G数据
# 假设机器支撑一年,hdfs保留3个副本,ods层100G*365*3=100T左右,10T*10个节点,后期可以继续扩容,考虑数仓分层和数据压缩再进一步评估

# 分层架构
# ods(Operational Data Store)：原始数据层,sqoop/canal/flume/kafka同步数据
# dwd(Data Warehouse Detail )：数据明细层,将ods层数据清洗和脱敏,保存业务事实明细,一行数据对应一次业务行为,比如下单
# dws(Data Warehouse Summary)：数据汇总层,将dwd层数据按天轻度汇总,一行数据对应主题对象一天的汇总行为,比如用户一天下单次数
# ads(Application Data Store)：应用数据层,按照各种业务指标聚合生成统计报表
# 分层好处：分解复杂任务方便定位问题、复用中间数据减少重复开发

# 离线数仓和实时数仓区别
# 数据架构：离线数仓还是传统架构(简单稳定),实时数仓是kappa架构(未来趋势),lambda架构介于两者之间(当前主流)
# 数据分层：实时数仓的数据层次更少,因为每多一个层级数据都会有一定的延迟
# 数据存储：离线数仓存储在hive(hdfs),实时数仓存储在kafka,地区和渠道等维度信息可能要依赖hbase/mysql/其它KV存储

# 函数依赖
# 学号  姓名  系名  系主任  课程  分数
# 101  张三  经济系  李强  概率论  95
# 102  李四  法律系  王伟  劳动法  99
# 完全函数依赖：(学号+课程)能推断出分数,但是单独用学号或课程推断不出分数,所以分数完全依赖于(学号,课程)
# 部分函数依赖：(学号+课程)能推断出姓名,但是单独用学号也能推断出姓名,所以姓名部分依赖于(学号,课程)
# 传递函数依赖：学号能推断出系名,系名能推断出系主任,但是系主任推断不出学号,所以系主任传递依赖于学号
                                                 
# 三大范式
# 设计数据库表结构的规范,优点是减少数据冗余,保证数据一致性,缺点是拆分成太多小表获取数据时需要join
# 第一范式：列不可分割
# 第二范式：不能存在部分函数依赖
# 第三范式：不能存在传递函数依赖

# 数据建模
# 关系建模：主要应用于OLTP系统,遵循三范式减少数据冗余,但是数据过于分散大数据场景下多表join查询效率低
# 维度建模：主要应用于OLAP系统,不遵循三范式存在数据冗余,将业务通过事实表和维度表呈现,表结构简单查询效率高
# 维度建模根据事实表和维度表的连接关系又分为星型模型和雪花模型,事实表的外键对应维度表的主键

# 维度表：对事实的描述信息(用户/商品/时间/地区),数据量很小
# 事实表：每行数据代表一个业务事件(下单/支付/退款/评论),包含指向各个维度的外键值(uid/pid/oid)及事实的度量值(次数/个数/金额),数据量较大

# 星型模型：所有维度表直接与事实表连接,存在数据冗余但是查询时join的表更少,并且维度表数据量较小而数仓的磁盘空间很大,以空间换时间提高查询效率
# 雪花模型：存在渐变维度,将星型模型的维度进一步细分,某个维度表通过其它维度表连接到事实表,减少数据冗余但是查询时join的表更多
# 星座模型：基于多个事实表,也是数据仓库的常态,和前两个模型不冲突,生产环境通常是混着用
# 建模步骤：选择业务 - 声明粒度(明细/汇总) - 确认维度 - 确认事实

# 数据脱敏
# 加密：通过udf将手机号码的4-11位都加1,然后4-7位和8-11位调换顺序,方便还原,安全程度取决于具体加密算法
# 掩码: 身份证变成320922******,只保留开头省市县信息且总长度不变,后期做用户归属地图表统计也不影响
# 重排：序号12345重排为54321,按照一定的顺序进行打乱,方便还原,但是也容易破解
# 截断：13811001111截断为138,舍弃必要信息保证数据模糊性,是比较常用的脱敏方法,但往往对生产不够友好

# 数据质量
# 及时性：批处理是否按时完成,针对耗时过长任务进行优化
# 唯一性：字段唯一性检查,是否有重复数据
# 完整性：记录数和字段数是否缺失,可以监控hive元数据制定相关规则引擎
# 准确性：生成数据的类型/格式/阈值是否准确
```

### 拉链表
```hiveql
-- 拉链表保存历史数据状态变化的同时可以节省空间,处理缓慢变化维场景
-- 1.mysql订单表结构为
create table if not exists orders (
order_id        int,
create_time     string,
update_time     string,
status          string
)
stored as textfile;

-- 2.数据仓库的ods层有一张订单分区表,存放每天的增量数据
create table if not exists ods_orders_inc (
order_id        int,
create_time     string,
update_time     string,
status          string
)
partitioned by (dt string)
stored as textfile;

-- 3.数据仓库的dw层有一张订单历史拉链表,存放订单的所有历史数据
create table if not exists dw_orders_his (
order_id        int,
create_time     string,
update_time     string,
status          string,
begin_date      string,  -- 该状态的生命周期开始时间
end_date        string   -- 该状态的生命周期结束时间,'9999-12-31'表示该状态仍有效,没有更新为下一个状态  
)
stored as textfile;

-- 查询当前所有有效记录(最新状态)
select * from dw_order_his where end_date = '9999-12-31';
-- 查询2019-06-21历史快照(2019-06-21这一天的数据变化情况)
-- 新增: begin_date = '2019-06-21' and end_date = '9999-12-31'
-- 更新: begin_date < '2019-06-21' and end_date = '2019-06-21'
-- 未变: begin_date < '2019-06-21' and end_date = '9999-12-31'
select * from dw_order_his where begin_date <= '2019-06-21' and end_date >= '2019-06-21';

-- 全量初始化
-- 假设在20190821这天做全量初始化,那么需要将包括20190820之前的所有数据都抽取到ods并刷新到dw
-- 1.抽取全量数据到ods
insert overwrite table ods_orders_inc partition (dt=20190820)
select order_id,create_time,update_time,status from orders where create_time <= '2019-08-20';
-- 2.从ods刷新到dw
insert overwrite table dw_orders_his
select order_id,create_time,update_time,status,create_time as begin_date,'9999-12-31' as end_date from ods_orders_inc where dt=20190820;

-- 增量刷新历史数据
-- 从20190822开始,需要每天刷新前一天的更新数据到历史表
-- 1.通过增量抽取,先将2019-08-21的数据抽取到ods
insert overwrite table ods_orders_inc partition (dt=20190821)
select order_id,create_time,update_time,status from orders where create_time = '2019-08-21' or update_time = '2019-08-21';
-- 2.关联dw_orders_his历史数据(截止到20190820)和ods_orders_inc增量数据(20190821)放入临时表
insert overwrite table dw_orders_his_tmp
select *
from (
    -- 20190821这天新增的数据,即create_time='2019-08-21',直接加进来
    select *,'2019-08-21' as begin_date,'9999-12-31' as end_date from ods_orders_inc where dt=20190821 and create_time='2019-08-21'
    union all
    -- 20190821这天更新的数据,即update_time='2019-08-21',再加上没有变化的那大部分历史数据,需要关联两张表
    select a.order_id,a.create_time,a.update_time,a.status,a.begin_date,
           -- 能关联上说明状态有变化,end_date更新为前一天;关联不上说明状态没有变化,end_date保持不变
           case when b.order_id is not null then '2019-08-20' else a.end_date end as end_date
    from dw_orders_his a
    left join
    (select * from ods_orders_inc where dt=20190821 and create_time < '2019-08-21') b on a.order_id = b.order_id
) t
order by order_id,begin_date;
-- 刷新临时表数据到拉链表
insert overwrite table dw_orders_his select * from dw_orders_his_tmp;
```

### 用户行为分析
```sql
-- 新增用户：日活表left join新增表,新增表中mid为空的即为新增用户
insert into table dws_new_mid_day
select t1.*,current_date
from dws_uv_detail_day t1
left join dws_new_mid_day t2 on t1.mid_id = t2.mid_id
where t1.dt=current_date and t2.mid_id is null;

-- 留存用户：日活表join新增表前1/3/7/15天
insert overwrite table dws_user_retention_day partition(dt=20190101)
select t2.*,1 retention_day
from dws_uv_detail_day t1 join dws_new_mid_day t2 on t1.mid_id = t2.mid_id
where t1.dt=current_date and t2.create_date = date_add(current_date,-1);  -- 1/3/7/15日留存分别减1/3/7/15

-- 沉默用户：只在下载当天启动过,且启动时间是在7天前
insert into table ads_silent_count
select current_date,count(*) silent
from
    (select dev_id from dws_uv_detail_day where dt <= current_date group by dev_id having count(*) = 1 and min(dt) < date_sub(current_date, 7)) t1
group by current_date;

-- 流失用户：最近7天都没有登录
insert into table ads_wastage_count
select current_date,count(*) wastage
from
    (select dev_id from dws_uv_detail_day group by dev_id having max(dt) <= date_sub(current_date, 7)) t1
group by current_date;
```