### hadoop2.7
```shell script
# 解压安装包
[root@cdh1 opt]$ tar -xvf hadoop-2.7.2.tar.gz -C /opt/module
[root@cdh1 opt]$ tar -xvf apache-hive-1.2.1-bin.tar.gz -C /opt/module
# bin目录是一些原始命令  hadoop/hdfs/yarn/mapred/run-eample/spark-shell/spark-submit/spark-sql
# sbin目录是一些服务(启动/停止)命令  start/stop
# 添加到环境变量
[root@cdh1 ~]$ vim /etc/profile
export HADOOP_HOME=/opt/module/hadoop-2.7.2
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export HIVE_HOME=/opt/module/hive-1.2.1
export PATH=$PATH:$HIVE_HOME/bin:$HIVE_HOME/sbin
# 修改hadoop-env
[root@cdh1 hadoop]$ vim hadoop-env.sh
export JAVA_HOME=/usr/java/jdk1.8.0_181-cloudera
# 修改slaves
[root@cdh1 hadoop]$ vim slaves
cdh1
cdh2
cdh3
# 修改hive-env
[root@cdh1 conf]$ vim hive-env.sh
export HADOOP_HOME=/opt/module/hadoop-2.7.2
export HIVE_CONF_DIR=/opt/module/hive-1.2.1/conf
# 配置hive元数据到mysql,在hive的conf目录新增hive-site.xml
[root@cdh1 ~]$ cp /usr/share/java/mysql-connector-java-5.1.46.jar /opt/module/hive-1.2.1/lib/
# 修改完全部配置文件后拷贝到其它节点
[root@cdh1 module]$ scp -r hadoop-2.7.2/ cdh2:/opt/module/
[root@cdh1 module]$ scp -r hadoop-2.7.2/ cdh3:/opt/module/
# 一键分发脚本
[root@cdh1 ~]$ cd /usr/bin & vim xsync & chmod +x xsync
#!/bin/bash
# 获取参数
if [ $# == 1 ]; then
    path=$1  # 文件要写全路径
else
    echo "Usage: <file>"
    exit
fi
# 获取文件(夹)绝对路径
file=$(basename ${path})
# 获取文件(夹)所在目录
dir=$(dirname ${path})
# 获取当前用户
user=$(whoami)
# 遍历节点分发
for ((i=2;i<=10;i++)); 
do
    echo "=============== cdh${i} ==============="
    rsync -rv ${dir}/${file} ${user}@cdh${i}:${dir}
done
```

### spark2.1
```shell script
# 解压安装包
[root@cdh1 ~]$ tar -xvf spark-2.1.1-bin-hadoop2.7.tgz -C /opt/module
# 添加到环境变量
[root@cdh1 ~]$ vim /etc/profile
export SPARK_HOME=/opt/module/spark-2.1.1-bin-hadoop2.7
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin

# This file is sourced when running various Spark programs.
[root@cdh1 ~]$ vim spark-env.sh
# java环境
JAVA_HOME=/usr/java/jdk1.8.0_181-cloudera
# on yarn模式,只能从hdfs读数据,通过yarn管理资源和任务监控(8088端口)
HADOOP_CONF_DIR=/opt/module/hadoop-2.7.2/etc/hadoop
SPARK_DRIVER_MEMORY=512M
SPARK_EXECUTOR_CORES=1
SPARK_EXECUTOR_INSTANCES=2
SPARK_EXECUTOR_MEMORY=512M
SPARK_HISTORY_OPTS="-Dspark.history.fs.logDirectory=hdfs://cdh1:9000/user/spark/history"
# standalone模式,只能从本地读数据,spark自己管理资源和任务监控(8080端口)
SPARK_MASTER_HOST=cdh1
SPARK_MASTER_PORT=7077
SPARK_WORKER_CORES=1
SPARK_WORKER_INSTANCES=1
SPARK_WORKER_MEMORY=512M
SPARK_DAEMON_JAVA_OPTS="
-Dspark.deploy.recoveryMode=ZOOKEEPER
-Dspark.deploy.zookeeper.url=cdh1,cdh2,cdh3
-Dspark.deploy.zookeeper.dir=/spark"
SPARK_HISTORY_OPTS="-Dspark.history.fs.logDirectory=hdfs://cdh1:9000/user/spark/history"

# Default system properties included when running spark-submit.
[root@cdh1 ~]$ vim spark-defaults.conf
spark.eventLog.enabled     true
# 日志目录需提前创建好
spark.eventLog.dir         hdfs://cdh1:9000/user/spark/history

# 拷贝到其它节点
[root@cdh1 opt]$ scp -r spark-2.1.1/ cdh2:/opt/module
[root@cdh1 opt]$ scp -r spark-2.1.1/ cdh3:/opt/module

# 一键启动/关闭集群
[root@cdh1 ~]$ start-cluster

# 本地测试(日志格式：local-timestamp)
[root@cdh1 ~]$ run-example org.apache.spark.examples.SparkPi
[root@cdh1 ~]$ run-example org.apache.spark.examples.streaming.NetworkWordCount localhost 9999

# 提交任务到yarn(日志格式：application_timestamp_0001)
[root@cdh1 ~]$ spark-submit --class org.apache.spark.examples.SparkPi --master yarn --deploy-mode client ./examples/jars/spark-examples_2.11-2.1.1.jar
[root@cdh1 ~]$ spark-submit --class org.apache.spark.examples.mllib.LinearRegression --master yarn --deploy-mode cluster --jars ./examples/jars/*  hdfs://cdh1:9000/data/sample_linear_regression_data.txt
# 参数解析
--class <main-class>           # application的启动类
--master <master-url>          # master地址,local/yarn
--deploy-mode <deploy-mode>    # 部署模式,client(默认)/cluster
--file                         # 配置文件
--conf <key>=<value>           # 配置属性
--verbose                      # 输出额外的debug信息
<application-jar>              # 包含application和dependencies的jar包路径
[application-arguments]        # 传给main方法的参数
--driver-memory 512M           # driver可用内存,默认1G
--executor-memory 512M         # executor可用内存,默认1G
```

### cluster
```shell script
# 手动启动集群
# 启动zk
[root@cdh1 ~]$ zkServer.sh start
# 格式化namenode
[root@cdh1 ~]$ hdfs namenode -format
# 把tmp拷到nn2下面
[root@cdh1 hadoop-2.7.2]$ scp -r hadoop-2.7.2/tmp cdh2:/opt/module/hadoop-2.7.2
# 格式化ZKFC
[root@cdh1 ~]$ hdfs zkfc -formatZK
# 启动hdfs
[root@cdh1 ~]$ start-dfs.sh
# 启动yarn
[root@cdh1 ~]$ start-yarn.sh
# cdh2要手动启
[root@cdh2 ~]$ yarn-daemon.sh start resourcemanager
# 启动mr历史日志
[root@cdh1 ~]$ mr-jobhistory-daemon.sh start historyserver

# 一键启动集群
[root@cdh1 ~]$ cd /usr/bin & vim start-cluster & chmod +x start-cluster
#!/bin/bash
# 启动zookeeper
for i in cdh1 cdh2 cdh3
do
    echo ==================== ${i} ====================
    # ssh后面的命令是未登录执行,需要先刷新系统环境变量
    ssh ${i} "source /etc/profile && zkServer.sh start"
    echo ${?}
done
# 启动hdfs
start-dfs.sh
# 启动yarn
start-yarn.sh
# cdh2要手动启动
ssh cdh2 "source /etc/profile && yarn-daemon.sh start resourcemanager"
# 开启mr的jobhistory
mr-jobhistory-daemon.sh start historyserver
# 启动spark
/opt/module/spark-2.1.1-bin-hadoop2.7/sbin/start-all.sh
# 开启spark的history-server
/opt/module/spark-2.1.1-bin-hadoop2.7/sbin/start-history-server.sh

# 在所有节点执行某个命令
[root@cdh1 ~]$ cd /usr/bin & vim xcall.sh & chmod +x xcall.sh
[root@cdh1 ~]$ xcall.sh jps | xcall.sh "cd /tmp/logs && rm -rf *"
#!/bin/bash
for i in cdh1 cdh2 cdh3
do
    echo ==================== ${i} ====================
    # ssh后面的命令是未登录执行,需要先刷新系统环境变量,$*表示输入的所有参数
    ssh ${i} "source /etc/profile && $*"
done

# 一键关闭集群
[root@cdh1 ~]$ cd /usr/bin & vim stop-cluster & chmod +x stop-cluster
#!/bin/bash
# 关闭kafka
for i in cdh1 cdh2 cdh3
do
    echo ==================== ${i} ====================
    # ssh后面的命令是未登录执行,需要先刷新系统环境变量
    ssh ${i} "source /etc/profile && cd /opt/module/kafka_2.11-0.11.0.2/bin && kafka-server-stop.sh"
    echo ${?}
done
# 关闭hdfs
stop-dfs.sh
# 关闭yarn
stop-yarn.sh
# cdh2要手动关闭
ssh cdh2 "source /etc/profile && yarn-daemon.sh stop resourcemanager"
# 关闭mr的jobhistory
mr-jobhistory-daemon.sh stop historyserver
# 关闭spark
/opt/module/spark-2.1.1-bin-hadoop2.7/sbin/stop-all.sh
# 开启spark的history-server
/opt/module/spark-2.1.1-bin-hadoop2.7/sbin/stop-history-server.sh
# 关闭zookeeper
for i in cdh1 cdh2 cdh3
do
    echo ==================== ${i} ====================
    # ssh后面的命令是未登录执行,需要先刷新系统环境变量
    ssh ${i} "source /etc/profile && zkServer.sh stop"
    echo ${?}
done
```

### fsimage排查hdfs小文件
```shell script
# cdh界面告警,存在隐患: DataNode有1008598个块,警告阈值1000000块
# 获取fsimage信息
[root@cdh1 ~]$ hdfs dfsadmin -fetchImage /data
[root@cdh1 ~]$ ll -h /data/fsimage_0000000000264065803
-rw-rw-r-- 1 deploy deploy 150M Dec 23 10:47 /data/fsimage_0000000000264065803
# 格式化fsimage为可读文本
[root@cdh1 ~]$ hdfs oiv -i /data/fsimage_0000000000264065803 -o /data/fsimage.csv -p Delimited -delimiter ","
[root@cdh1 ~]$ head /data/fsimage.csv
[root@cdh1 ~]$ sed -i "1d" /data/fsimage.csv  # 删除首行表头
# 创建存储fsimage的hive表
CREATE TABLE `fsimage_info_csv`(
  `path` string, 
  `replication` int, 
  `modificationtime` string, 
  `accesstime` string, 
  `preferredblocksize` bigint, 
  `blockscount` int, 
  `filesize` bigint, 
  `nsquota` string, 
  `dsquota` string, 
  `permission` string, 
  `username` string, 
  `groupname` string)
ROW FORMAT SERDE 
  'org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe' 
WITH SERDEPROPERTIES ( 
  'field.delim'=',', 
  'serialization.format'=',') 
STORED AS INPUTFORMAT 
  'org.apache.hadoop.mapred.TextInputFormat' 
OUTPUTFORMAT 
  'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat';
# 加载数据到hive表  
[root@cdh1 ~]$ sudo -u hdfs hdfs dfs -put /data/fsimage.csv /data/hive/warehouse/fsimage_info_csv/
# 查看文件大小分布
[root@cdh1 ~]$ hdfs oiv -p FileDistribution -i fsimage_0000000000264065803 -o fs_distribution
[root@cdh1 ~]$ cat fs_distribution
Processed 0 inodes.
Processed 1048576 inodes.
Size	NumFiles
2097152	1300936
...
totalFiles = 1345611
totalDirectories = 248231
totalBlocks = 1344047
totalSpace = 3221988629132
maxFileSize = 10737925589
# 逐级目录统计文件数量,根据结果反向找到涉及程序,尝试优化避免产生过多小文件
SELECT
    dir_path,
    COUNT(*) AS small_file_num 
FROM
    (
     SELECT
         relative_size,
         dir_path 
     FROM
         (
          SELECT
              CASE filesize < 128000000 WHEN TRUE THEN 'small' ELSE 'large' END AS relative_size,
              # 具体精确到database/table/dt可以自定义
              concat('/',split(PATH,'\/')[1],'/',split(PATH,'\/')[2],'/',split(PATH,'\/')[3],'/',split(PATH,'\/')[4],'/',split(PATH,'\/')[5]) AS dir_path 
          FROM
               fsimage_info_csv 
          WHERE
               permission LIKE 'd%') t1
     WHERE
         relative_size = 'small') t2 
GROUP BY
    dir_path 
ORDER BY
    small_file_num desc 
limit 100;
```

### hue
```shell script
# 解决hue10万行下载限制
# 以管理员账号admin登录查看配置信息
Hue Administration - Configuration - beeswax - download_cell_limit(默认100000行*100列=10000000)
[root@master1 ~]$ find / -name beeswax
/opt/cloudera/parcels/CDH-5.14.2-1.cdh5.14.2.p0.3/lib/hue/apps/beeswax
[root@master1 ~]$ vim /opt/cloudera/parcels/CDH-5.14.2-1.cdh5.14.2.p0.3/lib/hue/apps/beeswax/src/beeswax/conf.py
DOWNLOAD_CELL_LIMIT = Config(
  key='download_cell_limit',
  default=100000000,
# hue查询结果字段带有表名
CM - Hive - 配置 - hiveserver2 - hive-site.xml的HiveServer2高级配置代码段(安全阀) - hive.resultset.use.unique.column.names=false
```