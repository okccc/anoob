### install
- [es和kibana下载地址](https://www.elastic.co/cn/downloads/?elektra=home&storm=hero)
- [ik分词器下载地址](https://github.com/medcl/elasticsearch-analysis-ik/releases)
```shell script
# 安装es
[root@cdh1 ~]$ tar -xvf elasticsearch-7.9.0.tar.gz -C /opt/module/
# 查看版本,kibana和ik分词器要和es保持版本一致
[root@cdh1 ~]$ elasticsearch --version
Version: 7.9.0, Build: default/tar/a479a2a7fce0389512d6a9361301708b92dff667/2020-08-11T21:36:48.204330Z, JVM: 14.0.1
# 修改yml配置文件,": "后面必须有空格
[root@cdh1 ~]$ vim config/elasticsearch.yml
cluster.name: my-es                     # 集群名称
node.name: node-1                       # 节点名称
network.host: cdh1                      # ip地址
http.port: 9200                         # 端口默认9200
discovery.seed_hosts: ["cdh1", "cdh2"]  # 自发现配置,新节点向集群报到的主机名
# 调整jvm启动内存大小
[root@cdh1 ~]$ vim config/jvm.options
-Xms1g
-Xmx1g
# 安装ik中文分词器,必须放到es的plugins目录下,分词就是将所有词汇分好放到elasticsearch-7.9.0/plugins/ik/config下的文件中
[root@cdh1 ~]$ unzip elasticsearch-analysis-ik-7.9.0.zip -d /opt/module/elasticsearch-7.9.0/plugins/ik
# 自定义词库,有时候词库并不包含项目中的专业术语或网络用语,可以在本地或远程扩展词库
[root@cdh1 ~]$ vim plugins/ik/config/IKAnalyzer.cfg.xml
<properties>
    <comment>IK Analyzer 扩展配置</comment>
    <!--用户可以在这里配置自己的扩展字典 -->
    <entry key="ext_dict">./myword.txt</entry>
    <!--用户可以在这里配置自己的扩展停止词字典-->
    <entry key="ext_stopwords"></entry>
    <!--用户可以在这里配置远程扩展字典 -->
    <!-- <entry key="remote_ext_dict">words_location</entry> -->
    <!--用户可以在这里配置远程扩展停止词字典-->
    <!-- <entry key="remote_ext_stopwords">words_location</entry> -->
</properties>
# 分发并修改node.name和network.host
[root@cdh1 ~]$ xsync /opt/module/elasticsearch-7.9.0
# 启动
[root@cdh1 ~]$ bin/elasticsearch
# 关闭
[root@cdh1 ~]$ ps -ef | grep -i 'elastic' | grep -v grep | awk '{print $2}' | xargs kill
# 测试连接
[root@cdh1 ~]$ curl http://localhost:9200/_cat/nodes?v
ip        heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
127.0.0.1           19          98  10    2.65                  mdi       *      node-1
# 查看日志
[root@cdh1 ~]$ tail -f /opt/module/elasticsearch-7.9.0/logs/my-es.log

# 安装kibana
[root@cdh1 ~]$ tar -xvf kibana-7.9.0-darwin-x86_64.tar.gz -C /opt/module/
# 修改yml配置文件
[root@cdh1 ~]$ vim config/kibana.yml
server.host: "0.0.0.0"  # 授权远程访问
server.port: 5601       # 端口默认5601
elasticsearch.hosts: ["http://cdh1:9200", "http://cdh2:9200"]  # 指定es集群地址,逗号分隔
# 启动(要先启动es)
[root@cdh1 ~]$ bin/kibana
# 关闭
[root@cdh1 ~]$ ps -ef | grep -i 'kibana' | grep -v grep | awk '{print $2}' | xargs kill
# 测试连接
[root@cdh1 ~]$ http://localhost:5601/app/dev_tools#/console

# 一键启动es集群
[root@cdh1 ~]$ vim es.sh & chmod +x es.sh
#!/bin/bash 
es_home=/opt/module/elasticsearch-7.9.0
kibana_home=/opt/module/kibana-7.9.0-darwin-x86_64
case $1 in
"start"){
    for i in cdh1 cdh2 cdh3
    do
        echo "=============== ${i}启动es ==============="
        ssh ${i} "source /etc/profile && ${es_home}/bin/elasticsearch > /dev/null 2>&1 &"
    done
    echo "=============== 启动kibana ==============="
    nohup ${kibana_home}/bin/kibana > ${kibana_home}/logs/kibana.log 2>&1 &
};;
"stop"){
    echo "=============== 停止kibana ==============="
    ps -ef | grep kibana | grep -v grep | awk '{print \$2}' | xargs kill
    for i in cdh1 cdh2 cdh3
    do
        echo "=============== ${i}停止es ==============="
        ssh ${i} "ps -ef | grep -i 'elastic' | grep -v grep | awk '{print \$2}' | xargs kill" > /dev/null 2>&1
    done
};;
esac
```

### es
```shell script
# elasticsearch是基于Lucene的企业级搜索引擎,基于restful web接口,是一个近实时的搜索平台,从生成文档索引到文档可搜索,有1秒的轻微延迟
# kibana可以搜索存储在es索引中的数据并与之交互,实现数据分析和可视化并以图表形式展现,kibana本身只是一个工具,不涉及集群并发量也不大
cluster
# 集群：es默认是集群状态,哪怕只有一个节点,cluster.name参数设置集群唯一名称标识,节点都是通过该名称加入集群
node
# 节点：存储数据,参与集群的索引和搜索功能,es启动时会给节点分配一个UUID,集群包含一个或多个节点
index
# 索引：相当于mysql的table和mongodb的collection,可以crud
document
# 文档：相当于mysql的row,用json表示,一个索引包含多个文档
field
# 字段：相当于mysql的column,一个文档包含多个字段
shards & replicas
# 索引会存储大量数据,假设10亿文档将占用1TB磁盘,可能会超过单节点硬件限制,因此es提供了索引分片功能,每个分片都是功能齐全的独立索引
# 索引可以分片,分片可以创建副本,es创建索引时默认分配一个分片(主分片)和一个副本(副分片),可通过_shrink和_split动态更改(不建议)
# 集群中可以将主分片和副本分片放到不同节点,分片(节点)故障时可以提高可用性,并发搜索多个分片可以提高吞吐量

# es对比mysql
public class Movie {String id; String name; Double score; List<Actor> actorList;}
public class Actor {String id; String name;}
# 这两个java实体类如果保存在mysql会被拆成2张表,但是es可以用一个json来表示一个document
{"id": "1", "name": "red sea", "score": "8.5", "actorList": [{"id": "1", "name": "aaa"}, {"id": "3", "name": "bbb"}]}
```


### RestFulApi(DSL)
```shell script
# DSL(Domain Specific Language) 特定领域专用语言
# 全局操作,?v显示头信息
GET /_cat/indices?v  # 查看默认索引,health/status/index/uuid/pri/rep/docs.count/docs.deleted/store.size/pri.store.size
GET /_cat/health?v   # 查看集群健康状况,green正常 yellow单点正常 red故障
GET /_cat/nodes?v    # 查看节点状况
GET /_cat/shards?v   # 查看所有索引分片情况,/shards/${movie_index}可以指定索引
GET /_cat/{...}?v    # 其他系统默认信息

# 索引操作
PUT/GET/DELETE ${index_name}     # 创建/查看/删除索引,索引必须是小写字母,es不支持修改索引结构
GET /_cat/aliases?v              # 查看索引别名
POST _aliases                    # add添加别名,remove删除别名,应用场景：给相似的索引起相同别名,达到分组目的,通过别名查询组内所有索引
#{"actions": [{"add": {"index": "${index_name}","alias": "${index_name_alias}"}}]}
#{"actions": [{"remove": {"index": "${index_name}","alias": "${index_name_alias}"}}]}
GET /_cat/templates?v            # 查看索引模板
PUT/GET /_template/${tmp_index}  # 创建/查看模板,应用场景：根据时间间隔(日/月/年)分割业务索引,可以随时间灵活改变索引结构以及查询范围优化
#{"index_patterns": ["order*"], "settings": {"number_of_shards": 1}, "aliases": {"{index}-query": {}, "order-query":{}},
#"mappings": {"properties": {"id": {"type": "keyword"}, "name": {"type": "text","analyzer": "ik_smart"}}}}

# 文档操作
PUT/GET/DELETE ${index_name}/_doc/${doc_id}  # 创建/查看/删除文档,如果doc_id已存在直接覆盖
#{"id":100, "name":"red sea", "doubanScore":8.5, "actorList":[{"id":1,"name":"zhang yi"},{"id":2,"name":"hai qing"}]}
GET ${index_name}/_search?pretty             # 查看索引所有文档
POST ${index_name}/_doc                      # 生成随机id创建文档
POST ${index_name}/_update/${doc_id}         # 更新文档,doc是固定写法
#{"doc": {"name": "red sea"}}
POST ${index_name}/_bulk                     # _bulk表示批处理,批量操作的json要写在同一行
#{"index":{"_id":11}}
#{"id":100,"name":"red sea","doubanScore":5.0,"actorList":[{"id":4,"name":"aaa"}]}
#{"index":{"_id":12}}
#{"id":200,"name":"blue sea","doubanScore":5.0,"actorList":[{"id":4,"name":"bbb"}]}
#{"update": {"_id": "11"}}
#{"doc": {"name": "green sea"}}
#{"delete": {"_id": "12"}}

```