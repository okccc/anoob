### install
```shell script
# es/kibana下载地址 https://www.elastic.co/cn/downloads/?elektra=home&storm=hero
# postman下载地址 https://www.postman.com/
# ik分词器下载地址 https://github.com/medcl/elasticsearch-analysis-ik/releases
# 安装es
[root@cdh1 ~]$ tar -xvf elasticsearch-7.9.0.tar.gz -C /opt/module/
# 查看版本,kibana和ik分词器要和es保持版本一致
[root@cdh1 ~]$ elasticsearch --version
Version: 7.9.0, Build: default/tar/a479a2a7fce0389512d6a9361301708b92dff667/2020-08-11T21:36:48.204330Z, JVM: 14.0.1
# 修改yml配置文件,": "后面必须有空格
[root@cdh1 ~]$ vim config/elasticsearch.yml
cluster.name: my-es                     # 集群名称
node.name: node-1                       # 节点名称
network.host: cdh1                      # ip地址
http.port: 9200                         # 端口默认9200
discovery.seed_hosts: ["cdh1", "cdh2"]  # 自发现配置,新节点向集群报到的主机名
# 调整jvm启动内存大小
[root@cdh1 ~]$ vim config/jvm.options
-Xms1g
-Xmx1g
# 安装ik中文分词器,必须放到es的plugins目录下,分词就是将所有词汇分好放到elasticsearch-7.9.0/plugins/ik/config下的文件中
[root@cdh1 ~]$ unzip elasticsearch-analysis-ik-7.9.0.zip -d /opt/module/elasticsearch-7.9.0/plugins/ik
# 自定义词库,有时候词库并不包含项目中的专业术语或网络用语,可以在本地或远程扩展词库
[root@cdh1 ~]$ vim plugins/ik/config/IKAnalyzer.cfg.xml
<properties>
    <comment>IK Analyzer 扩展配置</comment>
    <!--用户可以在这里配置自己的扩展字典 -->
    <entry key="ext_dict">./myword.txt</entry>
    <!--用户可以在这里配置自己的扩展停止词字典-->
    <entry key="ext_stopwords"></entry>
    <!--用户可以在这里配置远程扩展字典 -->
    <!-- <entry key="remote_ext_dict">words_location</entry> -->
    <!--用户可以在这里配置远程扩展停止词字典-->
    <!-- <entry key="remote_ext_stopwords">words_location</entry> -->
</properties>
# 分发并修改node.name和network.host
[root@cdh1 ~]$ xsync /opt/module/elasticsearch-7.9.0
# 启动
[root@cdh1 ~]$ bin/elasticsearch
# 关闭
[root@cdh1 ~]$ ps -ef | grep -i 'elastic' | grep -v grep | awk '{print $2}' | xargs kill
# 测试连接
[root@cdh1 ~]$ curl http://localhost:9200/_cat/nodes?v
ip        heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
127.0.0.1           19          98  10    2.65                  mdi       *      node-1
# 查看日志
[root@cdh1 ~]$ tail -f /opt/module/elasticsearch-7.9.0/logs/my-es.log

# 安装kibana
[root@cdh1 ~]$ tar -xvf kibana-7.9.0-darwin-x86_64.tar.gz -C /opt/module/
# 修改yml配置文件
[root@cdh1 ~]$ vim config/kibana.yml
server.host: "0.0.0.0"  # 授权远程访问
server.port: 5601       # 端口默认5601
elasticsearch.hosts: ["http://cdh1:9200", "http://cdh2:9200"]  # 指定es集群地址,逗号分隔
# 启动(要先启动es)
[root@cdh1 ~]$ bin/kibana
# 关闭
[root@cdh1 ~]$ ps -ef | grep -i 'kibana' | grep -v grep | awk '{print $2}' | xargs kill
# 测试连接
[root@cdh1 ~]$ http://localhost:5601/app/dev_tools#/console

# 一键启动es集群
[root@cdh1 ~]$ vim es.sh & chmod +x es.sh
#!/bin/bash
es_home=/opt/module/elasticsearch-7.9.0
kibana_home=/opt/module/kibana-7.9.0-darwin-x86_64
case $1 in
"start"){
    for i in cdh1 cdh2 cdh3
    do
        echo "=============== ${i}启动es ==============="
        ssh ${i} "source /etc/profile && ${es_home}/bin/elasticsearch > /dev/null 2>&1 &"
    done
    echo "=============== 启动kibana ==============="
    nohup ${kibana_home}/bin/kibana > ${kibana_home}/logs/kibana.log 2>&1 &
};;
"stop"){
    echo "=============== 停止kibana ==============="
    ps -ef | grep kibana | grep -v grep | awk '{print \$2}' | xargs kill
    for i in cdh1 cdh2 cdh3
    do
        echo "=============== ${i}停止es ==============="
        ssh ${i} "ps -ef | grep -i 'elastic' | grep -v grep | awk '{print \$2}' | xargs kill" > /dev/null 2>&1
    done
};;
esac
```

### rest
```shell script
# web：分布式系统为互联网资源提供访问入口,url定位资源,rest就是用http动作对资源做crud操作
# rest(Representational State Transfer)：资源的表述性状态转移,是web服务的一种风格不是标准,符合rest原则的架构就称之为restful
# Representational资源的表现形式,比如json/xml/jpeg | State Transfer资源的状态变化,通过get/post/put/delete等http动词实现
# url的作用就是用来定位具体资源,url本身不应该包含/get这样的动词,具体的crud操作通过http协议的动词实现
# RestFulApi：DSL(Domain Specific Language)特定领域专用语言,可借助Postman调试,直接导入es-postman.json
# soap面向服务
Get http://localhost/QueryUser
Get http://localhost/CreateUser
Get http://localhost/ModifyUser
Get http://localhost/DeleteUser
# rest面向资源
Get http://localhost/user
POST http://localhost/user
PUT http://localhost/user
DELETE http://localhost/user
```

### es
```shell script
# elasticsearch是基于Lucene的企业级搜索引擎,是一个近实时的搜索平台,基于简单的restful api隐藏lucene的复杂性,让全文搜索变得简单
# kibana可以搜索存储在es索引中的数据并与之交互,实现数据分析和可视化并以图表形式展现,kibana本身只是一个工具,不涉及集群并发量也不大
cluster
# 集群：es默认是集群状态,哪怕只有一个节点,cluster.name参数设置集群唯一名称标识,节点都是通过该名称加入集群
node
# 节点：存储数据,参与集群的索引和搜索功能,es启动时会给节点分配一个UUID,集群包含一个或多个节点
index
# 索引：相当于mysql的table和mongodb的collection,可以crud
document
# 文档：相当于mysql的row,用json表示,一个索引包含多个文档
field
# 字段：相当于mysql的column,一个文档包含多个字段
shards & replicas
# 索引会存储大量数据,假设10亿文档将占用1TB磁盘,可能会超过单节点硬件限制,因此es提供了索引分片功能,每个分片都是功能齐全的独立索引
# 索引可以分片,分片可以创建副本,es创建索引时默认分配一个分片(主分片)和一个副本(副分片),可通过_shrink和_split动态更改(不建议)
# 集群中可以将主分片和副本分片放到不同节点,分片(节点)故障时可以提高可用性,并发搜索多个分片可以提高吞吐量

# es对比mysql
public class Movie {String id; String name; Double score; List<Actor> actorList;}
public class Actor {String id; String name;}
# 这两个java实体类如果保存在mysql会被拆成2张表,但是es可以用一个json来表示一个document
{"id": "1", "name": "red sea", "score": "8.5", "actorList": [{"id": "1", "name": "aaa"}, {"id": "3", "name": "bbb"}]}

# 搜索引擎中每个文件都对应一个id,文件是一系列关键词的集合,正向索引按照主键查找文档需要全局扫描,倒排索引按照关键词找到主键再去查文档
id    content               |     keyword    id
01    my name is grubby     |     name       01,02
02    my name is moon       |     moon       02
```