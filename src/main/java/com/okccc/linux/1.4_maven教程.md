### maven核心概念
```shell script
# maven是一款自动化构建工具,用于项目的构建和依赖管理
# 1.pom(project object model)：项目对象模型,以坐标方式添加依赖,maven就会从中央仓库下载该jar包并同时下载它所依赖的其它jar包
# 2.maven工程结构：约定 > 配置 > 编码,能基于约定就不用配置(maven工程目录结构是固定的),能用配置解决就不要硬编码(jdbc连接信息),提升效率方便扩展
# 3.maven坐标：groupId公司或组织域名倒序 + 当前项目名称,artifactId当前项目的模块名称,version当前模块版本,通过坐标可以在仓库中找到对应jar包
# 4.maven依赖原则：最短路径者优先,路径相同时先声明者优先 A->B->C->X(1.0) A->D->X(2.0) X=2.0 | A->B->Y(1.0) A->C->Y(2.0) Y=1.0
# scope控制maven依赖范围
compile     # 参与项目的编译、测试、运行、打包,贯穿所有阶段,随项目一起发布(默认值)
provided    # 参与项目的编译、测试、运行,但是在打包阶段做了exclude,表示该依赖由jdk或服务器提供,避免jar包冲突,比如web开发的servlet-api.jar
runtime     # 不参与项目的编译,只参与测试和运行,比如JDBC驱动包是不需要编译的,运行时才会使用到
test        # 只参与项目的测试,比如Junit包
# 5.maven仓库和镜像
# 本地仓库：本地磁盘的某个目录/Users/okc/.m2/repository,为本地maven工程服务
# 远程仓库：私服,为当前局域网内maven工程服务 | 中央仓库 https://repo1.maven.org/maven2,为互联网所有maven工程服务,在国外速度很慢
# 仓库存放的是各种jar包和插件,maven工程会先检查本地仓库有就直接返回,没有就再请求远程仓库并缓存到本地仓库
# 镜像相当于拦截器,会将maven工程对远程仓库的请求重定向到指定镜像,分布在各大洲,减轻中央仓库压力,更快响应用户请求
# <mirrorOf>*</mirrorOf> 将所有仓库请求都转到当前镜像
# <mirrorOf>central</mirrorOf> 将中央仓库的请求转到当前镜像
# <mirrorOf>*,!repo1</miiroOf> 将除repo1外的所有仓库请求都转到当前镜像
# mirrors中配置多个mirror只有第一个会生效
<mirrors>
    <mirror>
        <id>aliyun</id>
        <mirrorOf>central</mirrorOf>
        <name>aliyun repository</name>
        <url>http://maven.aliyun.com/nexus/content/groups/public/</url>
    </mirror>
</mirrors>
# 6.maven生命周期
mvn -v             # 查看maven版本
mvn compile        # 编译项目源代码(多了target目录)
mvn test-compile   # 编译测试源代码(查看target目录变化)
mvn test           # 运行测试类,测试代码不会被打包或部署(查看target目录变化)
mvn package        # 将编译好的代码打包成可发布的格式,比如jar(查看target目录变化)
mvn install        # 将打好的jar包安装到本地maven仓库,可以让其它工程依赖(查看本地仓库目录变化)
mvn install:install-file -DgroupId=<自定义> -DartifactId=<自定义> -Dversion=<自定义> -Dpackaging=jar -Dfile=<绝对路径>
mvn clean package  # 编译项目并打jar包 -Dmaven.test.skip=true 表示跳过测试代码的编译和运行
mvn clean install  # 打完包后部署到本地仓库
mvn clean deploy   # 打完包后部署到本地仓库和远程仓库
# 7.maven插件和目标：maven的生命周期与插件目标相互绑定,以完成某个具体的构建任务,比如compile就是插件maven-compiler-plugin的一个功能
# 8.maven继承和聚合：父工程可以统一管理jar包和插件,子工程以继承的方式获取父工程资源,在父工程中将各个子工程聚集到一起统一管理
```

### maven依赖分析
```shell script
# 查看工程依赖树,-Dverbose会把被忽略的jar包(相同jar包的不同版本)也列出来,-Dincludes只显示指定的jar包,-Doutput输出到文件
mvn dependency:tree -Dverbose -Doutput=a.txt
mvn dependency:tree -Dverbose -Dincludes=commons-collections  # 查看commons-collections包冲突情况
# 每行一个jar包,compile编译成功,omitted for duplicate表示jar包重复(版本相同)被忽略,omitted for conflict表示jar包冲突(版本不同)被忽略
[INFO] com.okccc:anoob:jar:1.0-SNAPSHOT
[INFO] +- org.apache.hadoop:hadoop-common:jar:2.7.0:compile
[INFO] |  +- commons-collections:commons-collections:jar:3.2.1:compile
[INFO] |  \- commons-configuration:commons-configuration:jar:1.6:compile
[INFO] |     \- (commons-collections:commons-collections:jar:3.2.1:compile - omitted for duplicate)
[INFO] \- org.apache.flink:flink-java:jar:1.12.0:compile
[INFO]    \- org.apache.flink:flink-core:jar:1.12.0:compile
[INFO]       \- (commons-collections:commons-collections:jar:3.2.2:compile - omitted for conflict with 3.2.1)

# 分析工程依赖情况
mvn dependency:analyze-only -Dverbose
[INFO] Used declared dependencies found:  # 声明且使用的依赖
[INFO]    com.alibaba:fastjson:jar:1.2.76:compile
[INFO]    org.apache.spark:spark-core_2.12:jar:2.4.5:compile
[WARNING] Used undeclared dependencies found:  # 使用但未声明的依赖
[WARNING]    joda-time:joda-time:jar:2.9.3:compile
[WARNING]    org.slf4j:slf4j-api:jar:1.7.10:compile
[WARNING] Unused declared dependencies found:  # 声明但未使用的依赖
[WARNING]    org.projectlombok:lombok:jar:1.18.20:compile
[WARNING]    org.apache.hadoop:hadoop-client:jar:2.7.0:compile
# 查看重复声明的依赖
mvn dependency:analyze-duplicate -Dverbose
[INFO] No duplicate dependencies found in <dependencies/> or in <dependencyManagement/>

# 查看使用的远程仓库
mvn dependency:list-repositories
[INFO] Repositories Used by this build:
[INFO]       id: aliyunmaven
      url: https://maven.aliyun.com/repository/spring-plugin
   layout: default
snapshots: [enabled => true, update => daily]
 releases: [enabled => false, update => daily]

[INFO]       id: nexus-aliyun
      url: http://maven.aliyun.com/nexus/content/groups/public
   layout: default
snapshots: [enabled => false, update => daily]
 releases: [enabled => true, update => daily]
```

### maven常见错误
```shell script
# scala项目打jar包后找不到类
mvn package只会对java源码进行编译和打包,将jar包改成rar压缩文件,或者直接查看target/classes发现报错那个类没打进来
pom文件scala-maven-plugin添加execution标签,或者手动执行 mvn clean scala:compile compile package
mvn package只会对java源码包下的java代码和scala源码包下的scala代码进行编译和打包,所以java和scala代码不要混在一块

# 类加载器读不到resources目录配置文件
maven打包默认会将java/resources/scala三个包的内容都打进去,查看target/classes发现资源文件没进来,idea环境出问题了

# idea使用maven插件打包没问题,mvn package打包提示jdk冲突
idea自带的maven版本是3.6.3,本地安装的maven版本是3.5.4,不同版本解决jar包冲突的方式不一样,升级本地maven到最新版 brew install maven

# 运行flink报错Error: A JNI(Java Native Interface) error has occurred, please check your installation and try again
因为pom文件的依赖添加了<scope>provided</scopoe>,导致idea本地运行flink程序时缺少运行环境

# udf报错: Could not find artifact org.pentaho:pentaho-aggdesigner-algorithm:jar:5.1.5-jhyde
有些插件是第三方公司提供的,很多mvn仓库里没有,那就多加几个mvn仓库的镜像吧,pom.xml右键 - Maven - Open 'settings.xml' - mirror

# Cannot resolve com.github.RoaringBitmap:RoaringBitmap:0.9.9
点击idea右侧Maven依赖发现ru.yandex.clickhouse:clickhouse-jdbc:0.3.0报红,一般都是高版本jar包用到了不兼容的依赖,适当降低版本就行

# Caused by: com.fasterxml.jackson.databind.JsonMappingException: Incompatible Jackson version: 2.7.8
查看工程依赖树发现是hadoop相关依赖用到了这个不兼容的jar包,可以在dependency里面添加exclusion去除,或者直接降低hadoop版本

# Cannot Download Sources Sources not found for: org.apache.flink:flink-scala_2.12:1.12.0
mvn dependency:resolve -Dclassifier=sources 或者直接 mvn dependency:sources

# flink-sql报错：java.lang.IncompatibleClassChangeError: Implementing class
只引入flink相关依赖就没问题,说明是别的jar包和flink冲突了,由于工程中依赖太多不好调试,可以新建工程用控制变量法专门排查,最终发现是spark-hive

# Caused by: java.lang.ClassNotFoundException: com.google.protobuf.LiteralByteString
将jar包解压后看看是否包含当前报错类,如果包含那就是依赖冲突了,借助Maven Helper插件分析冲突jar包
mvn dependency:tree -Dverbose -Dincludes=com.google.protobuf -DoutputFile=./aaa.txt
分析依赖树发现mysql包的com.google.protobuf:protobuf-java:jar:3.6.1:compile导致hbase用不了,可以在mysql依赖添加exclusion去除
```